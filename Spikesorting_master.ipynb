{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab35c3f4-5ac6-46e1-8163-ab3bc79cf67a",
   "metadata": {},
   "source": [
    "# Load Data and check recording\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5d4bb0-6a24-4b99-a07d-d8ecb59f18c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ipywidgets available - interactive GUI ready\n"
     ]
    }
   ],
   "source": [
    "import spikeinterface.full as si\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import probeinterface as pi\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import os, sys\n",
    "import shutil\n",
    "from pprint import pprint \n",
    "import time as time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import bombcell as bc\n",
    "\n",
    "    \n",
    "global_job_kwargs = dict(n_jobs=8, chunk_duration=\"10s\",progress_bar=True)\n",
    "si.set_global_job_kwargs(**global_job_kwargs)\n",
    "\n",
    "\n",
    "basefolder=r\"D:\\3556-17\\3556-17_naive_g0\"\n",
    "base_path = Path(basefolder)\n",
    "metapath = base_path / 'Meta'\n",
    "if not os.path.isdir(metapath):\n",
    "   os.makedirs(metapath)\n",
    "\n",
    "\n",
    "\n",
    "recording =  si.read_spikeglx(basefolder, stream_id='imec0.ap', load_sync_channel=False)\n",
    "lfp = si.read_spikeglx(basefolder, stream_id='imec0.lf', load_sync_channel=False)\n",
    "event =  si.read_spikeglx(basefolder, stream_id='nidq', load_sync_channel=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60852e7-b850-420a-aa7f-0d680d0c5eba",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5eb59a8-b0c1-4059-8b17-6ca0a1500921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imec0.ap#AP191']\n",
      "CommonReferenceRecording: 384 channels - 29999.900000 Hz - 1 segments - 140,000,329 samples \n",
      "                          4,666.69s (1.30 hours) - int16 dtype - 100.14 GiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcf07c88a434c4fb5181d010e6f4e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(TimeSlider(children=(Dropdown(description='segment', options=(0,), value=0), Button(icon='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 4070 SUPER'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recording = si.ChannelSliceRecording(recording, channel_ids=recording.get_channel_ids()[180:330])\n",
    "rec1 = si.highpass_filter(recording, freq_min=400.)\n",
    "rec1 = si.phase_shift(rec1)\n",
    "bad_channel_ids, channel_labels = si.detect_bad_channels(rec1,method = 'coherence+psd')\n",
    "print(bad_channel_ids)\n",
    "rec1 = si.interpolate_bad_channels(recording=rec1, bad_channel_ids=bad_channel_ids)\n",
    "\n",
    "rec1 = si.common_reference(rec1, operator=\"median\", reference=\"global\")\n",
    "print(rec1)\n",
    "\n",
    "\n",
    "%matplotlib widget\n",
    "si.plot_traces({'raw':recording,'filtered':rec1}, backend='ipywidgets')\n",
    "\n",
    "from spikeinterface.sorters import installed_sorters\n",
    "installed_sorters()\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34675ab-7faf-4cb1-96c1-019e6a372c41",
   "metadata": {},
   "source": [
    "# Run Kilosort and postprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b014d-d25f-4d88-83fb-65ddcb9d79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Sorting_KS4 = si.run_sorter(sorter_name=\"kilosort4\", recording=rec1, folder=basefolder + str('/sorted'),remove_existing_folder=True)\n",
    "analyzer = si.create_sorting_analyzer(Sorting_KS4, rec1, sparse=True, format=\"memory\")\n",
    "\n",
    "analyzer.compute(['random_spikes', 'waveforms', 'templates', 'noise_levels','unit_locations','correlograms'],**global_job_kwargs)\n",
    "analyzer.compute('spike_amplitudes')\n",
    "analyzer.compute('principal_components', n_components = 5, mode=\"by_channel_local\",**global_job_kwargs)\n",
    "\n",
    "metric_names=['firing_rate', 'presence_ratio', 'snr','isi_violation', 'amplitude_cutoff']\n",
    "metrics = si.compute_quality_metrics(analyzer, metric_names=metric_names)\n",
    "\n",
    "\n",
    "amplitude_cutoff_thresh = 0.1\n",
    "isi_violations_ratio_thresh = 0.5\n",
    "presence_ratio_thresh = 0.9\n",
    "\n",
    "\n",
    "our_query = f\"(amplitude_cutoff < {amplitude_cutoff_thresh}) & (isi_violations_ratio < {isi_violations_ratio_thresh}) & (presence_ratio > {presence_ratio_thresh})\"\n",
    "\n",
    "keep_units = metrics.query(our_query)\n",
    "keep_unit_ids = keep_units.index.values\n",
    "analyzer_clean = analyzer.select_units(keep_unit_ids, folder=basefolder +str('/analyzer_clean'), format='binary_folder')\n",
    "print(analyzer)\n",
    "print(analyzer_clean)\n",
    "\n",
    "si.export_to_phy(analyzer_clean, output_folder= base_path / 'sorted',**global_job_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e29244-5c3f-4ad5-8b41-e8241a40b8a3",
   "metadata": {},
   "source": [
    "# examine Phy to create info.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0548315d-1bef-4111-8778-bcb250332bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = f\"{basefolder}\\\\sorted\\\\phy\\\\params.py\"\n",
    "!phy template-gui \"{param_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec42641-1b11-417c-bf16-053fb16fc73b",
   "metadata": {},
   "source": [
    "# Bombcell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea451426-df0c-4299-bd02-1a28dcca472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ks_dir = base_path / \"sorted\" / \"sorter_output\"\n",
    "last_part = base_path.name  t\n",
    "\n",
    "imec_dir = base_path / (last_part + \"_imec0\")\n",
    "raw_file_path = imec_dir / (last_part + \"_t0.imec0.ap.bin\")\n",
    "meta_file_path = imec_dir / (last_part + \"_t0.imec0.ap.meta\")\n",
    "\n",
    "\n",
    "# Bombcell output\n",
    "save_path = ks_dir / \"bombcell\"\n",
    "\n",
    "\n",
    "\n",
    "param = bc.get_default_parameters(ks_dir, \n",
    "                                  raw_file=raw_file_path,\n",
    "                                  meta_file=meta_file_path,\n",
    "                                  kilosort_version=4)\n",
    "(\n",
    "    quality_metrics,\n",
    "    param,\n",
    "    unit_type,\n",
    "    unit_type_string,\n",
    ") = bc.run_bombcell(\n",
    "    ks_dir, save_path, param\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0db079-ebdc-405c-90f2-2427f967d1f0",
   "metadata": {},
   "source": [
    "# Match Bombcell to SI and Phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe798b-ae16-4768-a9de-b997d6dfd2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read input files\n",
    "map_df = pd.read_csv(base_path / \"sorted\" / \"phy\" / \"cluster_si_unit_ids.tsv\", sep=\"\\t\")\n",
    "bc_df = pd.read_csv(base_path / \"sorted\" / \"sorter_output\" / \"bombcell\" / \"cluster_bc_unitType.tsv\", sep=\"\\t\")\n",
    "info_df = pd.read_csv(base_path / \"sorted\" / \"phy\" / \"cluster_info.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Merge by matching Kilosort IDs\n",
    "merged = map_df.merge(bc_df, left_on=\"si_unit_id\", right_on=\"cluster_id\", how=\"left\")\n",
    "\n",
    "# Extract labels\n",
    "phy_labels = merged[[\"cluster_id_x\", \"bc_unitType\"]].rename(columns={\"cluster_id_x\": \"cluster_id\"})\n",
    "\n",
    "# Merge labels into cluster info\n",
    "info_df = info_df.merge(phy_labels, on=\"cluster_id\", how=\"left\")\n",
    "\n",
    "# Optional label overwrite\n",
    "info_df[\"group\"] = info_df[\"bc_unitType\"]\n",
    "\n",
    "# Save output files\n",
    "phy_labels.to_csv(base_path / \"sorted\" / \"phy\" / \"cluster_bc_unitType.tsv\", sep=\"\\t\", index=False)\n",
    "info_df.to_csv(base_path / \"sorted\" / \"phy\" / \"cluster_info.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c74d9-f398-4ceb-8793-ae8ca968ed68",
   "metadata": {},
   "source": [
    "# find ITI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142e1c7-70ed-471f-86d0-32e70cdde80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup ---\n",
    "channel_idx = 1  # Adjust as needed\n",
    "channel_id = event.get_channel_ids()[channel_idx]\n",
    "sf = event.get_sampling_frequency()\n",
    "\n",
    "# --- Load entire trace ---\n",
    "trace = event.get_traces(channel_ids=[channel_id])\n",
    "signal = trace[:, 0]\n",
    "time_vector = np.arange(len(signal)) / sf\n",
    "\n",
    "# --- TTL edge detection ---\n",
    "def extract_ttl_edges(signal, time_vector, threshold=1000):\n",
    "    above_threshold = signal > threshold\n",
    "    changes = np.diff(above_threshold.astype(int))\n",
    "    \n",
    "    rising_indices = np.where(changes == 1)[0] + 1\n",
    "    falling_indices = np.where(changes == -1)[0] + 1\n",
    "\n",
    "    edge_indices = np.concatenate((rising_indices, falling_indices))\n",
    "    edge_types = np.array(['rising'] * len(rising_indices) + ['falling'] * len(falling_indices))\n",
    "\n",
    "    sort_order = np.argsort(edge_indices)\n",
    "    edge_indices = edge_indices[sort_order]\n",
    "    edge_types = edge_types[sort_order]\n",
    "\n",
    "    edge_times = time_vector[edge_indices]\n",
    "\n",
    "    return edge_times, edge_types, edge_indices\n",
    "\n",
    "edge_times, edge_types, edge_indices = extract_ttl_edges(signal, time_vector, threshold=100)\n",
    "\n",
    "# --- Plot with markers ---\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time_vector, signal, label='Analog signal')\n",
    "plt.plot(edge_times, signal[edge_indices], 'ro', label='TTL edges')\n",
    "plt.title(f\"TTL signal with edges - channel {channel_id}\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.ylim(0, max(signal) * 1.1)\n",
    "plt.show()\n",
    "\n",
    "# --- Save to CSV ---\n",
    "df_edges = pd.DataFrame({\n",
    "    'time_seconds': edge_times,\n",
    "    'edge_type': edge_types\n",
    "})\n",
    "df_edges.to_csv(metapath / \"ttl_edge_times.csv\"), index=False)\n",
    "print(\"TTL edge times saved to 'ttl_edge_times.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca18122-9f43-43ab-86b7-abf77c4831d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f6535-1db9-460d-99c5-fa84141f0bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_and_save_ttl_events(data, bits, save_path):\n",
    "    digital_signals = data.get_traces()\n",
    "    digital_word = digital_signals[:, 8]\n",
    "    print(digital_word)\n",
    "    sampling_rate = data.get_sampling_frequency()\n",
    "    for bit in bits:\n",
    "        # Extract TTL pulses for the current bit\n",
    "        ttl_timestamps = extract_ttl_from_bit(digital_word, bit, sampling_rate)\n",
    "        \n",
    "        ttl_df = pd.DataFrame(ttl_timestamps, columns=['timestamps'])\n",
    "        \n",
    "        filename = f'soundttl.csv'\n",
    "        \n",
    "        ttl_df.to_csv(f\"{save_path}/{filename}\", index=False)\n",
    "        print(f\"Extracted TTL event timestamps for bit {bit} saved to {filename}\")\n",
    "\n",
    "\n",
    "def extract_ttl_from_bit(digital_word, bit, sampling_rate, min_gap_s=5.0):\n",
    "    \"\"\"\n",
    "    Extract and plot TTL bursts, return first rising edge per train.\n",
    "    \"\"\"\n",
    "    ttl_signal = (digital_word >> bit) & 1  # isolate bit\n",
    "    time_axis = np.arange(len(ttl_signal)) / sampling_rate\n",
    "\n",
    "    # Plot full or cropped TTL signal\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.plot(time_axis, ttl_signal)\n",
    "    plt.title(f'Isolated Bit {bit} State (0 or 1)')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Bit State')\n",
    "    plt.ylim(-0.1, 1.5)\n",
    "    #plt.xlim(0, min(time_axis[-1], 10))  # plot first 10 seconds by default\n",
    "    plt.show()\n",
    "\n",
    "    # Rising edges (0 → 1)\n",
    "    rising_indices = np.where(np.diff(ttl_signal) > 0)[0]\n",
    "    rising_timestamps = rising_indices / sampling_rate\n",
    "\n",
    "    # Detect first rising edge of each train\n",
    "    if len(rising_timestamps) == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    first_in_trains = [rising_timestamps[0]]\n",
    "    for i in range(1, len(rising_timestamps)):\n",
    "        if rising_timestamps[i] - rising_timestamps[i - 1] > min_gap_s:\n",
    "            first_in_trains.append(rising_timestamps[i])\n",
    "\n",
    "    return np.array(first_in_trains)\n",
    "\n",
    "\n",
    "\n",
    "bits_to_extract = [1]  \n",
    "extract_and_save_ttl_events(event , bits_to_extract, metapath)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56406066-0e1e-4521-a899-7ecea919490d",
   "metadata": {},
   "source": [
    "# phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b875b9a-06a6-4415-bc3c-a467fd267fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = f\"{basefolder}\\\\sorted\\\\phy\\\\params.py\"\n",
    "!phy template-gui \"{param_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c26673-918a-423d-bc01-e6a8d5ca51f4",
   "metadata": {},
   "source": [
    "# transfer to meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee580601-a601-4bbe-8261-67830643d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = base_path / \"sorted\" / \"phy\" / \"cluster_info.tsv\"\n",
    "dst = metapath / \"cluster_info.tsv\")\n",
    "shutil.copy2(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de11e347-c39b-466f-a425-c9344c438d29",
   "metadata": {},
   "source": [
    "# optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1400f46e-28ec-4b23-bc21-ea6e99af2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = si.load_sorting_analyzer(r\"D:\\3556-17\\3556-17_naive_g0\\analyzer_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e5a661e-9f08-4b42-88e5-d784a5533e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82190e0b471848ce9f61ef6ec14ac160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noise_level (workers: 8 processes):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 28 is out of bounds for axis 0 with size 28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m sorting_analyzer \u001b[38;5;241m=\u001b[39m analyzer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# we need to compute some required extensions\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43msorting_analyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspike_locations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnoise_levels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquality_metrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# note that spike_locations are optional, but recommended to compute accurate spike depths\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# optionally, we can pass an LFP recording to compute RMS/PSD in the LFP band\u001b[39;00m\n\u001b[0;32m     11\u001b[0m recording_lfp \u001b[38;5;241m=\u001b[39m si\u001b[38;5;241m.\u001b[39mbandpass_filter(lfp, freq_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, freq_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\si_env\\lib\\site-packages\\spikeinterface\\core\\sortinganalyzer.py:1635\u001b[0m, in \u001b[0;36mSortingAnalyzer.compute\u001b[1;34m(self, input, save, extension_params, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   1631\u001b[0m             \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m   1632\u001b[0m                 ext_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m   1633\u001b[0m             ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSortingAnalyzer.compute(): Parameters specified for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which is not in the specified \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1634\u001b[0m             extensions[ext_name] \u001b[38;5;241m=\u001b[39m ext_params\n\u001b[1;32m-> 1635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_several_extensions(extensions\u001b[38;5;241m=\u001b[39mextensions, save\u001b[38;5;241m=\u001b[39msave, verbose\u001b[38;5;241m=\u001b[39mverbose, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjob_kwargs)\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1637\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSortingAnalyzer.compute() needs a str, dict or list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\si_env\\lib\\site-packages\\spikeinterface\\core\\sortinganalyzer.py:1782\u001b[0m, in \u001b[0;36mSortingAnalyzer.compute_several_extensions\u001b[1;34m(self, extensions, save, verbose, **job_kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m     extension_instance\u001b[38;5;241m.\u001b[39mset_params(save\u001b[38;5;241m=\u001b[39msave, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextension_params)\n\u001b[0;32m   1780\u001b[0m     extension_instances[extension_name] \u001b[38;5;241m=\u001b[39m extension_instance\n\u001b[1;32m-> 1782\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[43mextension_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pipeline_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1783\u001b[0m     all_nodes\u001b[38;5;241m.\u001b[39mextend(nodes)\n\u001b[0;32m   1785\u001b[0m job_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompute : \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m + \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(extensions_with_pipeline\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\si_env\\lib\\site-packages\\spikeinterface\\core\\sortinganalyzer.py:2718\u001b[0m, in \u001b[0;36mAnalyzerExtension.get_pipeline_nodes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pipeline_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   2715\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m   2716\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_nodepipeline\n\u001b[0;32m   2717\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyzerExtension.get_pipeline_nodes() must be called only when use_nodepipeline=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_pipeline_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\si_env\\lib\\site-packages\\spikeinterface\\postprocessing\\spike_locations.py:116\u001b[0m, in \u001b[0;36mComputeSpikeLocations._get_pipeline_nodes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m sorting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msorting_analyzer\u001b[38;5;241m.\u001b[39msorting\n\u001b[0;32m    115\u001b[0m peak_sign \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspike_retriver_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeak_sign\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 116\u001b[0m extremum_channels_indices \u001b[38;5;241m=\u001b[39m \u001b[43mget_template_extremum_channel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msorting_analyzer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeak_sign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeak_sign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m retriever \u001b[38;5;241m=\u001b[39m SpikeRetriever(\n\u001b[0;32m    121\u001b[0m     sorting,\n\u001b[0;32m    122\u001b[0m     recording,\n\u001b[0;32m    123\u001b[0m     channel_from_template\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    124\u001b[0m     extremum_channel_inds\u001b[38;5;241m=\u001b[39mextremum_channels_indices,\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    126\u001b[0m nodes \u001b[38;5;241m=\u001b[39m get_localization_pipeline_nodes(\n\u001b[0;32m    127\u001b[0m     recording,\n\u001b[0;32m    128\u001b[0m     retriever,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    133\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\si_env\\lib\\site-packages\\spikeinterface\\core\\template_tools.py:178\u001b[0m, in \u001b[0;36mget_template_extremum_channel\u001b[1;34m(templates_or_sorting_analyzer, peak_sign, mode, outputs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     return_in_uV \u001b[38;5;241m=\u001b[39m templates_or_sorting_analyzer\u001b[38;5;241m.\u001b[39mis_in_uV\n\u001b[1;32m--> 178\u001b[0m peak_values \u001b[38;5;241m=\u001b[39m \u001b[43mget_template_amplitudes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemplates_or_sorting_analyzer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeak_sign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeak_sign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_in_uV\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_in_uV\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m extremum_channels_id \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    182\u001b[0m extremum_channels_index \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\si_env\\lib\\site-packages\\spikeinterface\\core\\template_tools.py:105\u001b[0m, in \u001b[0;36mget_template_amplitudes\u001b[1;34m(templates_or_sorting_analyzer, peak_sign, mode, return_in_uV, abs_value)\u001b[0m\n\u001b[0;32m    102\u001b[0m templates_array \u001b[38;5;241m=\u001b[39m get_dense_templates_array(templates_or_sorting_analyzer, return_in_uV\u001b[38;5;241m=\u001b[39mreturn_in_uV)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m unit_ind, unit_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(unit_ids):\n\u001b[1;32m--> 105\u001b[0m     template \u001b[38;5;241m=\u001b[39m \u001b[43mtemplates_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43munit_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextremum\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peak_sign \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 28 is out of bounds for axis 0 with size 28"
     ]
    }
   ],
   "source": [
    "\n",
    "from spikeinterface.exporters import export_to_ibl_gui\n",
    "import spikeinterface.exporters as exp\n",
    "\n",
    "sorting_analyzer = analyzer\n",
    "\n",
    "# we need to compute some required extensions\n",
    "sorting_analyzer.compute(['random_spikes', 'templates', 'spike_amplitudes', 'spike_locations', 'noise_levels', 'quality_metrics'])\n",
    "# note that spike_locations are optional, but recommended to compute accurate spike depths\n",
    "\n",
    "# optionally, we can pass an LFP recording to compute RMS/PSD in the LFP band\n",
    "recording_lfp = si.bandpass_filter(lfp, freq_min=1, freq_max=300)\n",
    "# we can also decimate the LFP to speed up the process\n",
    "recording_lfp = si.decimate(recording_lfp, 10)\n",
    "\n",
    "# the export process is fast because everything is pre-computed\n",
    "export_to_ibl_gui(\n",
    "    sorting_analyzer=sorting_analyzer,\n",
    "    output_folder=r\"D:\\3556-17\\histology\\tiffs\\slices\\ibl_naive\",\n",
    "    lfp_recording=recording_lfp,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
